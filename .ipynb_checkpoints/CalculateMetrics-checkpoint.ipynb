{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "import spectral\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, cohen_kappa_score, confusion_matrix\n",
    "\n",
    "from utils import load_data, AA_andEachClassAccuracy, load_HSISAT, Patch, applyPCA, padWithZeros\n",
    "\n",
    "import keras.backend as k\n",
    "import tensorflow as tf\n",
    "\n",
    "k.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset correctly imported\n"
     ]
    }
   ],
   "source": [
    "# Select dataset. Options are 'Kochia', 'IP', 'PU', 'SA', or 'EUROSAT'\n",
    "dataset = 'IP'\n",
    "train_x, train_y = load_data(dataset=dataset, test=True)\n",
    "if dataset == 'Kochia':\n",
    "    classes = 3\n",
    "elif dataset == 'EUROSAT':\n",
    "    classes = 10\n",
    "else:\n",
    "    classes = int(np.max(train_y)) + 1\n",
    "print(\"Dataset correctly imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICT AND CALCULATE METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy99.922% (+/- 0.073%)\n",
      "Average accuracy99.872% (+/- 0.183%)\n",
      "Kappa accuracy99.911% (+/- 0.083%)\n",
      "Precision accuracy99.825% (+/- 0.249%)\n"
     ]
    }
   ],
   "source": [
    "windowSize = train_x.shape[1]\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "cvoa = []\n",
    "cvaa = []\n",
    "cvka = []\n",
    "cvpre = []\n",
    "cvrec = []\n",
    "cvf1 = []\n",
    "\n",
    "# Select Network. Options are 'hyper3dnet', 'hybridsn', 'spectrum',\n",
    "# 'resnet50' (expect for Kochia), or 'kochiafc' (only for Kochia)\n",
    "network = 'hyper3dnet'\n",
    "\n",
    "# Initialize\n",
    "confmatrices = np.zeros((10, int(classes), int(classes)))\n",
    "\n",
    "ntrain = 1\n",
    "model = None\n",
    "for train, test in kfold.split(train_x, train_y):\n",
    "\n",
    "    k.clear_session()\n",
    "\n",
    "    ytest = to_categorical(train_y[test], num_classes=classes).astype(np.int32)\n",
    "\n",
    "    # Load network and weights of the 'ntrain'-fold\n",
    "    model = load_model(\"weights/\" + dataset + \"/\" + network + \"/weights-\" + network + dataset + str(ntrain) + \".h5\")\n",
    "    model.trainable = False\n",
    "\n",
    "    # Predict results\n",
    "    ypred = model.predict(train_x[test])\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    sess = tf.compat.v1.Session()\n",
    "    with sess.as_default():\n",
    "        con_mat = tf.math.confusion_matrix(labels=np.argmax(ytest, axis=-1),\n",
    "                                           predictions=np.argmax(ypred, axis=-1)).numpy()\n",
    "    con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=3)\n",
    "    classes_list = list(range(0, int(classes)))\n",
    "    con_mat_df = pd.DataFrame(con_mat_norm, index=classes_list, columns=classes_list)\n",
    "    confmatrices[ntrain - 1, :, :] = con_mat_df.values\n",
    "\n",
    "    # Calculate metrics\n",
    "    oa = accuracy_score(np.argmax(ytest, axis=1), np.argmax(ypred, axis=-1))\n",
    "    confusion = confusion_matrix(np.argmax(ytest, axis=1), np.argmax(ypred, axis=-1))\n",
    "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
    "    kappa = cohen_kappa_score(np.argmax(ytest, axis=1), np.argmax(ypred, axis=-1))\n",
    "    prec, rec, f1, support = precision_recall_fscore_support(np.argmax(ytest, axis=1), np.argmax(ypred, axis=-1),\n",
    "                                                             average='macro')\n",
    "\n",
    "    # Add metrics to the list\n",
    "    cvoa.append(oa * 100)\n",
    "    cvaa.append(aa * 100)\n",
    "    cvka.append(kappa * 100)\n",
    "    cvpre.append(prec * 100)\n",
    "    cvrec.append(rec * 100)\n",
    "    cvf1.append(f1 * 100)\n",
    "\n",
    "    ntrain = ntrain + 1\n",
    "\n",
    "\n",
    "print(\"Overall accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvoa)), float(np.std(cvoa))))\n",
    "print(\"Average accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvaa)), float(np.std(cvaa))))\n",
    "print(\"Kappa accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvka)), float(np.std(cvka))))\n",
    "print(\"Precision accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvpre)), float(np.std(cvpre))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "windowSize = 25 \n",
    "X, y = load_HSISAT(dataset)\n",
    "height = y.shape[0]\n",
    "width = y.shape[1]\n",
    "X, pca = applyPCA(X, numComponents=30)\n",
    "X = padWithZeros(X, windowSize//2)\n",
    "\n",
    "# calculate the predicted image\n",
    "outputs = np.zeros((height, width))\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        target = int(y[i, j])\n",
    "        if target == 0:\n",
    "            continue\n",
    "        else:\n",
    "            image_patch = Patch(X, i, j, windowSize)\n",
    "            X_test_image = image_patch.reshape(1, image_patch.shape[0], image_patch.shape[1],\n",
    "                                               image_patch.shape[2]).astype('float32')\n",
    "            prediction = (model.predict(X_test_image))\n",
    "            prediction = np.argmax(prediction, axis=1)\n",
    "            outputs[i][j] = prediction + 1\n",
    "\n",
    "ground_truth = spectral.imshow(classes=y, figsize=(7, 7))\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('IP_GT.png', dpi=1200)\n",
    "predict_image = spectral.imshow(classes=outputs.astype(int), figsize=(7, 7))\n",
    "# plt.savefig('SA_resnet50.png', dpi=1200)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
